{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d854c2-6c99-492e-8000-22118675ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "for col in ['Transaction_ID', 'Customer_ID', 'Phone','Zipcode' ,'Age','Year' ,'Ratings']:\n",
    "    if data[col].isna().any():\n",
    "        # Calculating the mean of the column (ignoring NaN values)\n",
    "        col_mean = data[col].mean(skipna=True)\n",
    "\n",
    "        # Filling NaN values with the mean\n",
    "        data[col].fillna(col_mean, inplace=True)\n",
    "\n",
    "    # Converting the column to integer dtype\n",
    "    data[col] = data[col].astype(int)\n",
    "\n",
    "print(data.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date']).dt.strftime('%Y-%m-%d')\n",
    "data['Time'] = pd.to_datetime(data['Time']).dt.strftime('%H:%M:%S')\n",
    "\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Filter rows where any of the specified columns have value 0 or negative\n",
    "filtered_data = data[(data['Total_Purchases'] <= 0) | (data['Amount'] <= 0) | (data['Total_Amount'] <= 0)]\n",
    "\n",
    "print(filtered_data)\n",
    "\n",
    "\n",
    "data['Total_Purchases'] = data['Total_Purchases'].interpolate(direction='both')\n",
    "data['Amount'] = data['Amount'].interpolate(direction='both')\n",
    "\n",
    "data['Total_Amount'] = data['Total_Purchases'] * data['Amount']\n",
    "\n",
    "# Fill null values in categorical columns with mode                                      #same in Categorical col of you have more time some values then it was getting mode from it ...\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns                          # like : red,blue,gree,red  : then mode id red it was fill in : NAN values ......\n",
    "data[categorical_cols] = data[categorical_cols].fillna(data[categorical_cols].mode().iloc[0])\n",
    "\n",
    "cat_columns = data.select_dtypes(include=['object']).columns\n",
    "for col in cat_columns:\n",
    "    data[col].fillna(data[col].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "segmentation_features = data[['Total_Purchases', 'Total_Amount']].dropna()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(segmentation_features)\n",
    "\n",
    "inertia = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(scaled_features)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "\n",
    "sns.scatterplot(x=data['Total_Purchases'], y=data['Total_Amount'], hue=data['Cluster'], palette='viridis')\n",
    "plt.title('Customer Segmentation')\n",
    "plt.xlabel('Total Purchases')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "cluster_summary = data.groupby('Cluster').agg({\n",
    "    'Total_Purchases': ['mean', 'count', 'sum'],\n",
    "    'Total_Amount': ['mean', 'sum'],\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "cluster_summary.columns = ['Cluster',\n",
    "                           'Avg_Purchases', 'Customer_Count', 'Total_Purchases',\n",
    "                           'Avg_Amount', 'Total_Amount']\n",
    "\n",
    "print(\"Cluster Summary:\")\n",
    "print(cluster_summary)\n",
    "\n",
    "\n",
    "# Filter high-value customers (Cluster 2)\n",
    "high_value_customers = data[data['Cluster'] == 2]\n",
    "\n",
    "# Save this segment for marketing\n",
    "high_value_customers.to_csv('high_value_customers.csv', index=False)\n",
    "\n",
    "print(f\"Number of High-Value Customers: {len(high_value_customers)}\")\n",
    "\n",
    "\n",
    "# Filter low-value customers (Cluster 0)\n",
    "low_value_customers = data[data['Cluster'] == 0]\n",
    "\n",
    "# Save this segment for re-engagement\n",
    "low_value_customers.to_csv('low_value_customers.csv', index=False)\n",
    "\n",
    "print(f\"Number of Low-Value Customers: {len(low_value_customers)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example: Analyzing product preferences by cluster\n",
    "product_preferences = data.groupby(['Cluster', 'Product_Category']).size().unstack().fillna(0)\n",
    "\n",
    "print(\"Product Preferences by Cluster:\")\n",
    "print(product_preferences)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example: Track clusters over time (if you have a 'Year' column)\n",
    "cluster_trends = data.groupby(['Year', 'Cluster']).size().unstack(fill_value=0)\n",
    "\n",
    "print(\"Cluster Trends Over Time:\")\n",
    "print(cluster_trends)\n",
    "\n",
    "# Visualize the trends\n",
    "cluster_trends.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "plt.title(\"Cluster Distribution Over Time\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Use relevant features for prediction\n",
    "features = data[['Total_Purchases', 'Total_Amount']]\n",
    "target = data['Cluster']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "# Example: New customer data for prediction\n",
    "new_customer_data = pd.DataFrame({\n",
    "    'Total_Purchases': [10, 25, 5],\n",
    "    'Total_Amount': [1200, 4000, 500]\n",
    "})\n",
    "\n",
    "# Ensure only the same feature columns are used\n",
    "# (Matching the columns used during model training)\n",
    "predict_features = new_customer_data[['Total_Purchases', 'Total_Amount']]\n",
    "\n",
    "# Predict the cluster\n",
    "predicted_clusters = clf.predict(predict_features)\n",
    "\n",
    "# Add predictions to the new data\n",
    "new_customer_data['Predicted_Cluster'] = predicted_clusters\n",
    "print(new_customer_data)\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "file_name = 'customer_segmentation_model.pkl'\n",
    "pickle.dump(clf,open (file_name,'wb'))\n",
    "\n",
    "\n",
    "\n",
    "loaded_model=pickle.load(open(file_name,'rb'))\n",
    "\n",
    "\n",
    "\n",
    "input_data = pd.DataFrame({\n",
    "    'Total_Purchases': [10, 25, 5],\n",
    "    'Total_Amount': [1200, 4000, 500]\n",
    "})\n",
    "\n",
    "predictions = []  # To store predictions for each row\n",
    "for index in input_data.index:\n",
    "    row_data = input_data.loc[[index]]  # Get data for current row\n",
    "    row_data_as_numpy_array = np.asarray(row_data)\n",
    "    row_data_reshaped = row_data_as_numpy_array.reshape(1, -1)  # Reshape to (1, 2)\n",
    "    prediction = loaded_model.predict(row_data_reshaped)\n",
    "    predictions.append(prediction[0])  # Store prediction for current row\n",
    "\n",
    "print(predictions)  # Print all predictions\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction == 0:\n",
    "        print('Low Value Customer')\n",
    "    elif prediction == 1:\n",
    "        print('Mid Value Customer')\n",
    "    else:\n",
    "        print('High Value Customer')\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the trained clustering model\n",
    "joblib.dump(clf, 'customer_segmentation_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load('customer_segmentation_model.pkl')\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        # Get JSON data from request\n",
    "        data = request.json\n",
    "\n",
    "        # Input validation (check if required keys are present)\n",
    "        required_keys = ['Total_Purchases', 'Total_Amount']\n",
    "        if not all(key in data for key in required_keys):\n",
    "            return jsonify({'error': 'Missing required keys'}), 400\n",
    "\n",
    "        # Convert input JSON to DataFrame\n",
    "        input_data = pd.DataFrame(data)\n",
    "\n",
    "        # Ensure only the same features used in training are present\n",
    "        features = input_data[['Total_Purchases', 'Total_Amount']]\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = clf.predict(features)\n",
    "\n",
    "        # Add predictions to the response\n",
    "        input_data['Predicted_Cluster'] = predictions\n",
    "        response = input_data.to_dict(orient='records')\n",
    "\n",
    "        return jsonify(response)\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
